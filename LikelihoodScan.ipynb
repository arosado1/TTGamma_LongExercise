{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "from coffea import util, hist\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the output files produced from running the full analysis on condor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'Outputs/outputMCOther_ttgamma_condorFull_4jet.coffea'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-0f956c07d79f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0moutputMC\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Outputs/outputMCOther_ttgamma_condorFull_4jet.coffea'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0moutputMC\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Outputs/outputMCSingletop_ttgamma_condorFull_4jet.coffea'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0moutputMC\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Outputs/outputMCTTbar1l_ttgamma_condorFull_4jet.coffea'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0moutputMC\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Outputs/outputMCTTbar2l_ttgamma_condorFull_4jet.coffea'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0moutputMC\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Outputs/outputMCTTGamma_ttgamma_condorFull_4jet.coffea'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/uscms_data/d3/arosado/cmsdas2020/TTGamma/TTGamma_LongExercise/coffeaenv/lib/python3.6/site-packages/coffea/util.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(filename)\u001b[0m\n\u001b[1;32m     18\u001b[0m     '''Load a coffea file from disk\n\u001b[1;32m     19\u001b[0m     '''\n\u001b[0;32m---> 20\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mlz4\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfin\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcloudpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfin\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/uscms_data/d3/arosado/cmsdas2020/TTGamma/TTGamma_LongExercise/coffeaenv/lib/python3.6/site-packages/lz4/frame/__init__.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(filename, mode, encoding, errors, newline, block_size, block_linked, compression_level, content_checksum, block_checksum, auto_flush, return_bytearray, source_size)\u001b[0m\n\u001b[1;32m    829\u001b[0m         \u001b[0mblock_checksum\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mblock_checksum\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m         \u001b[0mauto_flush\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mauto_flush\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 831\u001b[0;31m         \u001b[0mreturn_bytearray\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_bytearray\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    832\u001b[0m     )\n\u001b[1;32m    833\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/uscms_data/d3/arosado/cmsdas2020/TTGamma/TTGamma_LongExercise/coffeaenv/lib/python3.6/site-packages/lz4/frame/__init__.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, filename, mode, block_size, block_linked, compression_level, content_checksum, block_checksum, auto_flush, return_bytearray, source_size)\u001b[0m\n\u001b[1;32m    508\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;34m'b'\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    509\u001b[0m                 \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m'b'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 510\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuiltins\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    511\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_closefp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    512\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmode_code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'Outputs/outputMCOther_ttgamma_condorFull_4jet.coffea'"
     ]
    }
   ],
   "source": [
    "outputMC = util.load(f'Outputs/outputMCOther_ttgamma_condorFull_4jet.coffea')\n",
    "outputMC.add(util.load(f'Outputs/outputMCSingletop_ttgamma_condorFull_4jet.coffea'))\n",
    "outputMC.add(util.load(f'Outputs/outputMCTTbar1l_ttgamma_condorFull_4jet.coffea'))\n",
    "outputMC.add(util.load(f'Outputs/outputMCTTbar2l_ttgamma_condorFull_4jet.coffea'))\n",
    "outputMC.add(util.load(f'Outputs/outputMCTTGamma_ttgamma_condorFull_4jet.coffea'))\n",
    "outputMC.add(util.load(f'Outputs/outputMCWJets_ttgamma_condorFull_4jet.coffea'))\n",
    "outputMC.add(util.load(f'Outputs/outputMCZJets_ttgamma_condorFull_4jet.coffea'))\n",
    "\n",
    "outputData = util.load(f'Outputs/outputData_ttgamma_condorFull_4jet.coffea')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouping= {'ttgamma': ['TTGamma_Dilepton','TTGamma_SingleLept','TTGamma_Hadronic'],\n",
    "           'ttbar'  : ['TTbarPowheg_Dilepton', 'TTbarPowheg_Semilept', 'TTbarPowheg_Hadronic'],\n",
    "           'Single top':['ST_s_channel', 'ST_tW_channel', 'ST_tbarW_channel', 'ST_tbar_channel', 'ST_t_channel'],\n",
    "           'Wgamma' : ['WGamma_01J_5f'],\n",
    "           'Zgamma' : ['ZGamma_01J_5f_lowMass'],\n",
    "           'Other'    : ['TTWtoLNu','TTWtoQQ','TTZtoLL','W1jets', 'W2jets', 'W3jets', 'W4jets','DYjetsM10to50', 'DYjetsM50','GJets_HT40To100', 'GJets_HT100To200', 'GJets_HT200To400', 'GJets_HT400To600', 'GJets_HT600ToInf', 'QCD_Pt20to30_Ele', 'QCD_Pt30to50_Ele', 'QCD_Pt50to80_Ele', 'QCD_Pt80to120_Ele', 'QCD_Pt120to170_Ele', 'QCD_Pt170to300_Ele', 'QCD_Pt300toInf_Ele', 'QCD_Pt20to30_Mu', 'QCD_Pt30to50_Mu', 'QCD_Pt50to80_Mu', 'QCD_Pt80to120_Mu', 'QCD_Pt120to170_Mu', 'QCD_Pt170to300_Mu', 'QCD_Pt300to470_Mu', 'QCD_Pt470to600_Mu', 'QCD_Pt600to800_Mu', 'QCD_Pt800to1000_Mu', 'QCD_Pt1000toInf_Mu']\n",
    "          }\n",
    "\n",
    "groupingPho= {\"Genuine\":slice(1,2),\n",
    "              \"MisIDele\": slice(2,3),\n",
    "              \"NonPrompt\":slice(3,5),\n",
    "             }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load histograms from MC and Data, to extract the number of events split by photon category and sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'outputMC' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-c78c14c6807b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutputMC\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'M3'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'lepFlavor'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'M3'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'dataset'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mhist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mr'dataset'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34mr'Samples'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msorting\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'placement'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mgrouping\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'category'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mhist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mr'category'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34mr'Category'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msorting\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'placement'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mgroupingPho\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'outputMC' is not defined"
     ]
    }
   ],
   "source": [
    "h = outputMC['M3'].sum('lepFlavor').sum('M3').group('dataset',hist.Cat(r'dataset',r'Samples',sorting='placement'),grouping)\n",
    "h = h.group('category',hist.Cat(r'category',r'Category',sorting='placement'),groupingPho)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'outputData' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-c2bd348c75ab>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mhData\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutputData\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'M3'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'lepFlavor'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'M3'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'dataset'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'category'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mnData\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhData\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'noweight'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'outputData' is not defined"
     ]
    }
   ],
   "source": [
    "hData = outputData['M3'].sum('lepFlavor').sum('M3').sum('dataset').sum('category')\n",
    "nData = hData.values()[('noweight',)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'h' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-e6f45e10de1d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mvals\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintegrate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'systematic'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'nominal'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mmcYield\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrouping\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mmcYield\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'h' is not defined"
     ]
    }
   ],
   "source": [
    "vals = h.integrate('systematic','nominal').values()\n",
    "mcYield = []\n",
    "\n",
    "for i, sample in enumerate(grouping.keys()):\n",
    "    mcYield.append([])\n",
    "    for j, category in enumerate(groupingPho.keys()):\n",
    "        v = vals[(category,sample)]\n",
    "        mcYield[-1].append(v)\n",
    "mcYield = np.array(mcYield)\n",
    "\n",
    "errs = h.integrate('systematic','nominal')._sumw2\n",
    "\n",
    "mcYieldErr = []\n",
    "for s in errs:\n",
    "    mcYieldErr.append(errs[s]**0.5)\n",
    "\n",
    "mcYieldErr = np.array(mcYieldErr)\n",
    "mcYieldErr.shape = (3,6)\n",
    "mcYieldErr = mcYieldErr.transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add in dictionaries of the results of the misidentified electron scale factor, photon purity, and top purity fits for the nominal and all systematic uncertainties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'nominal': 2.3318804702960123, 'eleEffWeightDown': 2.3634048038780833, 'eleEffWeightUp': 2.3010288490854256, 'muEffWeightDown': 2.331880192302395, 'muEffWeightUp': 2.331880192302395}\n"
     ]
    }
   ],
   "source": [
    "with open('Fitting/MisIDSF.json') as MisIDSFJson:\n",
    "    MisIDSFResults = json.load(MisIDSFJson)\n",
    "\n",
    "print(MisIDSFResults)    \n",
    "    \n",
    "#MisIDSFResults = {'nominal': 1.,}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'nominal': [0.8050381935807093, 0.018571564849648312], 'eleEffWeightDown': [0.8050875172642655, 0.01859754765243804], 'eleEffWeightUp': [0.8049891754069325, 0.01854567073802106], 'muEffWeightDown': [0.8050206881988561, 0.018596179334710947], 'muEffWeightUp': [0.8050556222956757, 0.018547024013870258]}\n"
     ]
    }
   ],
   "source": [
    "with open('Fitting/photonPurity.json') as photonPurityJson:\n",
    "    photonPurityResults = json.load(photonPurityJson)\n",
    "\n",
    "print(photonPurityResults)    \n",
    "\n",
    "#photonPurityResults = {'nominal': (0.5, 0.1),}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'nominal': [0.9201039699795295, 0.028745993819633917], 'eleEffWeightDown': [0.9205103717165873, 0.028712974971390436], 'eleEffWeightUp': [0.9196803893148017, 0.02877817580881863], 'muEffWeightDown': [0.9205668244974882, 0.028741813293427138], 'muEffWeightUp': [0.9196247909852127, 0.028749729160458627]}\n"
     ]
    }
   ],
   "source": [
    "with open('Fitting/topPurity.json') as topPurityJson:\n",
    "    topPurityResults = json.load(topPurityJson)\n",
    "\n",
    "print(topPurityResults)    \n",
    "    \n",
    "#topPurityResults = {'nominal': (0.75, 0.1),}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def likelihoodFunction(ttgammaSF=1., nonPromptSF=1., mcValues=None, mcValuesErr=None, photonPurity=None, topPurity=None, nData = None, photonPurityErr=None, topPurityErr=None):\n",
    "    mcValues[0] *= ttgammaSF\n",
    "    mcValuesErr[0] *= ttgammaSF\n",
    "\n",
    "    mcValues[:,-1] *= nonPromptSF\n",
    "    mcValuesErr[:,-1] *= nonPromptSF\n",
    "    \n",
    "    nMC = mcValues.sum()\n",
    "    nMCErr = (mcValuesErr**2).sum()**0.5\n",
    "\n",
    "    #nIso is the sum of the first two columsn of data (genuine and misID)\n",
    "    nIso = mcValues[:,0:2].sum()\n",
    "    nIsoErr = (mcValuesErr[:,0:2]**2).sum()**0.5\n",
    "\n",
    "    #nTop is the sum of the first two rows (ttgamma and ttbar)\n",
    "    nTop = mcValues[0:2].sum()\n",
    "    nTopErr = (mcValuesErr[0:2]**2).sum()**0.5\n",
    "\n",
    "    mcPhotonPurity    = nIso/nMC\n",
    "    mcPhotonPurityErr = (mcPhotonPurity) * ((nIsoErr/nIso)**2 + (nMCErr/nMC)**2)**0.5\n",
    "\n",
    "    mcTopPurity = nTop/nMC\n",
    "    mcTopPurityErr = mcTopPurity * ((nTopErr/nTop)**2 + (nMCErr/nMC)**2)**0.5\n",
    "    \n",
    "    \n",
    "    chi2 = ((photonPurity-mcPhotonPurity)**2/(photonPurityErr**2 + mcPhotonPurityErr**2) + \n",
    "            (topPurity - mcTopPurity)**2/(topPurityErr**2 + mcTopPurityErr**2) +\n",
    "            (nData - nMC)**2/(nData + nMCErr**2)\n",
    "           )\n",
    "    \n",
    "    return np.exp(-0.5*chi2)\n",
    "                \n",
    "    \n",
    "\n",
    "def maximizeLikelihood(fitData, \n",
    "                       ttgSF = None, nonPromptSF=None, \n",
    "                       startTTGamma = 1., startNonprompt = 1., \n",
    "                       nSteps = 100,\n",
    "                       verbose=False, \n",
    "                       find1sigma = False, \n",
    "                       nStepsErr = 20):\n",
    "\n",
    "\n",
    "    mcYield=fitData['mcYield']\n",
    "    mcYieldErr=fitData['mcYieldErr']\n",
    "    photonPurity=fitData['photonPurity']\n",
    "    photonPurityErr=fitData['photonPurityErr']\n",
    "    topPurity=fitData['topPurity']\n",
    "    topPurityErr=fitData['topPurityErr']\n",
    "    nData=fitData['nData']\n",
    "    \n",
    "    \n",
    "    if ttgSF is None:\n",
    "        ttgSF=startTTGamma\n",
    "        iTTGSteps = range(3)\n",
    "    else:\n",
    "        iTTGSteps = [1]\n",
    "\n",
    "    if nonPromptSF is None:\n",
    "        nonPromptSF=startNonprompt\n",
    "        iNPSteps = range(3)\n",
    "    else:\n",
    "        iNPSteps = [1]\n",
    "        \n",
    "    stepSize = 0.1\n",
    "    \n",
    "    lastStepLk = -1.\n",
    "\n",
    "    for steps in range(nSteps):\n",
    "\n",
    "        best_lk = -1\n",
    "        best_iTTG = -1\n",
    "        best_iNP = -1\n",
    "        \n",
    "        for iTTG in iTTGSteps:\n",
    "            for iNP in iNPSteps:\n",
    "                lk = likelihoodFunction(ttgammaSF = ttgSF + (iTTG-1)*stepSize , \n",
    "                                        nonPromptSF=nonPromptSF + (iNP-1)*stepSize, \n",
    "                                        mcValues=mcYield.copy(), mcValuesErr=mcYieldErr.copy(),\n",
    "                                        photonPurity=photonPurity, topPurity=topPurity, \n",
    "                                        photonPurityErr=photonPurityErr, topPurityErr=topPurityErr, \n",
    "                                        nData=nData)\n",
    "\n",
    "                if lk > best_lk:\n",
    "                    best_lk = lk\n",
    "                    best_iTTG = iTTG\n",
    "                    best_iNP = iNP\n",
    "\n",
    "        ttgSF = ttgSF+(best_iTTG-1)*stepSize\n",
    "        nonPromptSF = nonPromptSF + (best_iNP-1)*stepSize\n",
    "\n",
    "        if best_iTTG==best_iNP==1:\n",
    "            stepSize = stepSize/2.\n",
    "            lastStepLk=-1.\n",
    "\n",
    "        if verbose:\n",
    "            print(steps, ttgSF, nonPromptSF, stepSize, best_lk)\n",
    "            \n",
    "    if find1sigma:\n",
    "\n",
    "        ### scan for ttgSF down\n",
    "        ttgammaErr = 0.1\n",
    "        stepSize = 0.1\n",
    "        trend = 1\n",
    "        for step in range(nStepsErr):\n",
    "            _,_,_lk = maximizeLikelihood(fitData, \n",
    "                                         ttgSF = ttgSF - ttgammaErr, \n",
    "                                         nonPromptSF=None, \n",
    "                                         nSteps = 50,\n",
    "                                    )\n",
    "\n",
    "\n",
    "            NLL = -2*np.log(_lk/best_lk)\n",
    "\n",
    "            if NLL < 1:\n",
    "                if trend== -1:\n",
    "                    stepSize /= 2.\n",
    "                ttgammaErr += stepSize\n",
    "                trend=1\n",
    "            else:\n",
    "                if trend==1:\n",
    "                    stepSize /= 2.\n",
    "                ttgammaErr -= stepSize\n",
    "                trend=-1\n",
    "        ttgammaDown = -1*ttgammaErr\n",
    "\n",
    "        ### scan for ttgSF up\n",
    "        ttgammaErr = 0.1\n",
    "        stepSize = 0.1\n",
    "        trend = 1\n",
    "        for step in range(nStepsErr):\n",
    "            _,_,_lk = maximizeLikelihood(fitData, \n",
    "                                         ttgSF = ttgSF + ttgammaErr, \n",
    "                                         nonPromptSF=None, \n",
    "                                         nSteps = 50,\n",
    "                                        )\n",
    "\n",
    "            NLL = -2*np.log(_lk/best_lk)\n",
    "\n",
    "            if NLL < 1:\n",
    "                if trend== -1:\n",
    "                    stepSize /= 2.\n",
    "                ttgammaErr += stepSize\n",
    "                trend=1\n",
    "            else:\n",
    "                if trend==1:\n",
    "                    stepSize /= 2.\n",
    "                ttgammaErr -= stepSize\n",
    "                trend=-1\n",
    "        ttgammaUp = ttgammaErr\n",
    "\n",
    "        ### scan for npSF down\n",
    "        npErr = 0.1\n",
    "        stepSize = 0.1\n",
    "        trend = 1\n",
    "        for step in range(nStepsErr):\n",
    "            _,_,_lk = maximizeLikelihood(fitData, \n",
    "                                         ttgSF = None, \n",
    "                                         nonPromptSF=nonPromptSF - npErr, \n",
    "                                         nSteps = 50,\n",
    "                                        )            \n",
    "\n",
    "            NLL = -2*np.log(_lk/best_lk)\n",
    "\n",
    "            if NLL < 1:\n",
    "                if trend== -1:\n",
    "                    stepSize /= 2.\n",
    "                npErr += stepSize\n",
    "                trend=1\n",
    "            else:\n",
    "                if trend==1:\n",
    "                    stepSize /= 2.\n",
    "                npErr -= stepSize\n",
    "                trend=-1\n",
    "        nonPromptDown = -1*npErr\n",
    "\n",
    "        ### scan for npSF up        \n",
    "        npErr = 0.1\n",
    "        stepSize = 0.1\n",
    "        trend = 1\n",
    "        for step in range(nStepsErr):\n",
    "            _,_,_lk = maximizeLikelihood(fitData, \n",
    "                                         ttgSF = None, \n",
    "                                         nonPromptSF=nonPromptSF + npErr,\n",
    "                                         nSteps = 50,                                         \n",
    "                                        )            \n",
    "\n",
    "            NLL = -2*np.log(_lk/best_lk)\n",
    "\n",
    "            if NLL < 1:\n",
    "                if trend== -1:\n",
    "                    stepSize /= 2.\n",
    "                npErr += stepSize\n",
    "                trend=1\n",
    "            else:\n",
    "                if trend==1:\n",
    "                    stepSize /= 2.\n",
    "                npErr -= stepSize\n",
    "                trend=-1\n",
    "        nonPromptUp = npErr        \n",
    "        \n",
    "        return ttgSF, ttgammaUp, ttgammaDown, nonPromptSF, nonPromptUp, nonPromptDown, best_lk\n",
    "        \n",
    "    else:\n",
    "        return ttgSF, nonPromptSF, best_lk\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run likelihood fit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate nominal scale factors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'MisIDSFResults' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-e8b0ac93530a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmisIDEleSF\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMisIDSFResults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'nominal'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mmcYield\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*=\u001b[0m \u001b[0mmisIDEleSF\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mmcYieldErr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*=\u001b[0m \u001b[0mmisIDEleSF\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'MisIDSFResults' is not defined"
     ]
    }
   ],
   "source": [
    "misIDEleSF = MisIDSFResults['nominal']\n",
    "\n",
    "mcYield[:,1] *= misIDEleSF\n",
    "mcYieldErr[:,1] *= misIDEleSF\n",
    "\n",
    "\n",
    "fitData = {\n",
    "    'mcYield':mcYield, \n",
    "    'mcYieldErr':mcYieldErr,\n",
    "    'photonPurity':photonPurityResults['nominal'][0], \n",
    "    'photonPurityErr':photonPurityResults['nominal'][1],\n",
    "    'topPurity':topPurityResults['nominal'][0],\n",
    "    'topPurityErr':topPurityResults['nominal'][1], \n",
    "    'nData':nData, \n",
    "}\n",
    "\n",
    "output = maximizeLikelihood(fitData,\n",
    "                        nSteps=100, \n",
    "                        find1sigma=True, \n",
    "                        nStepsErr=100, \n",
    "                        startTTGamma=1,\n",
    "                        startNonprompt=1\n",
    "                       )\n",
    "bestTTGSF, bestTTGSF_Up, bestTTGSF_Down, bestNPSF, bestNPSF_Up, bestNPSF_Down, mxLk = output                                                                                                         \n",
    "print(\"TTGamma SF = %.4f +%.4f %.4f\"%(bestTTGSF, bestTTGSF_Up, bestTTGSF_Down))\n",
    "print(\"nonPrompt SF = %.4f +%.4f %.4f\"%(bestNPSF, bestNPSF_Up, bestNPSF_Down))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run fit for all systematic uncertainties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'h' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-127c2af14688>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msyst\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msystematics\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mvals\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintegrate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'systematic'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msyst\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0mmcYield\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'h' is not defined"
     ]
    }
   ],
   "source": [
    "systematics = list(photonPurityResults.keys())\n",
    "systematics.remove('nominal')\n",
    "\n",
    "systResults = {}\n",
    "\n",
    "for syst in systematics:\n",
    "    vals = h.integrate('systematic',syst).values()\n",
    "    mcYield = []\n",
    "\n",
    "    for i, sample in enumerate(grouping.keys()):\n",
    "        mcYield.append([])\n",
    "        for j, category in enumerate(groupingPho.keys()):\n",
    "            v = vals[(category,sample)]\n",
    "            mcYield[-1].append(v)\n",
    "    mcYield = np.array(mcYield)\n",
    "\n",
    "    errs = h.integrate('systematic',syst)._sumw2\n",
    "\n",
    "    mcYieldErr = []\n",
    "    for s in errs:\n",
    "        mcYieldErr.append(errs[s]**0.5)\n",
    "\n",
    "    mcYieldErr = np.array(mcYieldErr)\n",
    "    mcYieldErr.shape = (3,6)\n",
    "    mcYieldErr = mcYieldErr.transpose()\n",
    "\n",
    "    misIDEleSF = MisIDSFResults[syst]\n",
    "\n",
    "    mcYield[:,1] *= misIDEleSF\n",
    "    mcYieldErr[:,1] *= misIDEleSF\n",
    "\n",
    "    \n",
    "    fitDataSyst = {\n",
    "        'mcYield':mcYield, \n",
    "        'mcYieldErr':mcYieldErr,\n",
    "        'photonPurity':photonPurityResults[syst][0], \n",
    "        'photonPurityErr':photonPurityResults[syst][1],\n",
    "        'topPurity':topPurityResults[syst][0],\n",
    "        'topPurityErr':topPurityResults[syst][1], \n",
    "        'nData':nData, \n",
    "    }\n",
    "    \n",
    "    output = maximizeLikelihood(fitDataSyst,\n",
    "                            nSteps=100, \n",
    "                            find1sigma=False, \n",
    "                            nStepsErr=100, \n",
    "                            startTTGamma=1,\n",
    "                            startNonprompt=1\n",
    "                           )\n",
    "    bestTTGSF, bestNPSF, bestLk = output\n",
    "    systResults[syst] = bestTTGSF\n",
    "\n",
    "print (systResults)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Likelihood scan plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make plots of likelihood scans for ttgamma scale factor and non prompt scale factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lkVals = []\n",
    "ttgVals = np.arange(0,2.,.01)\n",
    "for ttgSF in ttgVals:\n",
    "    _ttg, _np, _lk = maximizeLikelihood(fitData, ttgSF = ttgSF, nSteps=50)\n",
    "    lkVals.append(-2*np.log(_lk/mxLk))\n",
    "\n",
    "lkVals = np.array(lkVals)\n",
    "\n",
    "plt.scatter(ttgVals[lkVals<6],lkVals[lkVals<6],color='blue')\n",
    "plt.scatter(ttgVals[lkVals<4],lkVals[lkVals<4],color='yellow')\n",
    "plt.scatter(ttgVals[lkVals<1],lkVals[lkVals<1],color='green')\n",
    "plt.ylabel(\"2*NLL\")\n",
    "plt.xlabel(\"$t\\overline{t}\\gamma$ SF\")\n",
    "\n",
    "ttgVals2Sig = ttgVals[lkVals<5]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lkVals = []\n",
    "npVals = np.arange(0,2.,.01)\n",
    "for npSF in npVals:\n",
    "    _ttg, _np, _lk = maximizeLikelihood(fitData, nonPromptSF= npSF, nSteps=50)\n",
    "    lkVals.append(-2*np.log(_lk/mxLk))\n",
    "\n",
    "lkVals = np.array(lkVals)\n",
    "\n",
    "plt.scatter(npVals[lkVals<6],lkVals[lkVals<6],color='blue')\n",
    "plt.scatter(npVals[lkVals<4],lkVals[lkVals<4],color='yellow')\n",
    "plt.scatter(npVals[lkVals<1],lkVals[lkVals<1],color='green')\n",
    "plt.ylabel(\"2*NLL\")\n",
    "plt.xlabel(\"Nonprompt SF\")\n",
    "\n",
    "npVals2Sig = npVals[lkVals<5]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lkVals = []\n",
    "for npSF in npVals2Sig:\n",
    "    _lkVals = []\n",
    "    for ttg in ttgVals2Sig:\n",
    "        _ttg, _np, _lk = maximizeLikelihood(fitData, ttgSF= ttg, nonPromptSF= npSF, nSteps=1)\n",
    "        _lkVals.append(-2*np.log(_lk/mxLk))\n",
    "    lkVals.append(_lkVals)\n",
    "lkVals = np.array(lkVals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.contourf(ttgVals2Sig, npVals2Sig, lkVals, [0,1,4],colors=['green','yellow'])\n",
    "plt.plot(bestTTGSF, bestNPSF,marker='+',color='black',markersize=12,markeredgewidth=3);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "coffeaenv",
   "language": "python",
   "name": "coffeaenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
