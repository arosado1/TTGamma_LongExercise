{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eleEffWeightDown': (0.8050875172642655, 0.01859754765243804),\n",
      " 'eleEffWeightUp': (0.8049891754069325, 0.01854567073802106),\n",
      " 'muEffWeightDown': (0.8050206881988561, 0.018596179334710947),\n",
      " 'muEffWeightUp': (0.8050556222956757, 0.018547024013870258),\n",
      " 'nominal': (0.8050381935807093, 0.018571564849648312)}\n"
     ]
    }
   ],
   "source": [
    "#By Arun & Angel\n",
    "\n",
    "from ROOT import TFile, TFractionFitter, TObjArray\n",
    "import json\n",
    "import pprint\n",
    "\n",
    "## open root file, created from the SaveHistogramsToRoot step, containing charged hadron isolation distributions which have been grouped into isolated and nonprompt categories\n",
    "_file = TFile(\"../RootFiles/Isolation_Output.root\")\n",
    "\n",
    "## List of systematics\n",
    "systematics  = [\"nominal\",\n",
    "#                \"FSRDown\",\n",
    "#                \"FSRUp\",\n",
    "#                \"ISRDown\",\n",
    "#                \"ISRUp\",\n",
    "#                \"JERDown\",\n",
    "#                \"JERUp\",\n",
    "#                \"JESDown\",\n",
    "#                \"JESUp\",\n",
    "#                \"PDFDown\",\n",
    "#                \"PDFUp\",\n",
    "#                \"Q2ScaleDown\",\n",
    "#                \"Q2ScaleUp\",\n",
    "#                \"btagWeight_heavyDown\",\n",
    "#                \"btagWeight_heavyUp\",\n",
    "#                \"btagWeight_lightDown\",\n",
    "#                \"btagWeight_lightUp\",\n",
    "                \"eleEffWeightDown\",\n",
    "                \"eleEffWeightUp\",\n",
    "                \"muEffWeightDown\",\n",
    "                \"muEffWeightUp\",\n",
    "#                \"puWeightDown\",\n",
    "#                \"puWeightUp\",\n",
    "]\n",
    "\n",
    "results = {}\n",
    "\n",
    "## Get data from the input root file\n",
    "data = _file.Get(\"dataObs\")\n",
    "\n",
    "## Loop over the list of systematics\n",
    "for syst in systematics:\n",
    "    \n",
    "    ## Add histograms from Isolated and NonPrompt categories to the array 'mc'\n",
    "    mc = TObjArray(2)\n",
    "    \n",
    "    mc.Add(_file.Get(\"Isolated_\"+syst))\n",
    "    mc.Add(_file.Get(\"NonPrompt_\"+syst))\n",
    "   \n",
    "     ## Fit the MC histograms to data \n",
    "    fit = TFractionFitter(data,mc,\"q\")\n",
    "    \n",
    "    ## fit.Fit() actually performs the fit\n",
    "    ## check the fit status\n",
    "    status = int(fit.Fit())\n",
    "    \n",
    "    ## status==0 corresponds to fits that converged, and we can then obtain the fit result \n",
    "    fitResults = (fit.GetFitter().Result().Parameters()[0],fit.GetFitter().Result().Parameters()[1])\n",
    "    \n",
    "    ## Calculating the scale factor for isolated photons \n",
    "    isolatedSF  = data.Integral()*fitResults[0]/mc[0].Integral()\n",
    "    \n",
    "    ## Similarly, calculate the scale factor for the nonprompt photons\n",
    "    nonPromptSF = data.Integral()*fitResults[1]/mc[1].Integral()\n",
    "    \n",
    "    ## Calculate the number of events with isolated photons, using the isolatedSF\n",
    "    isolatedRate = mc[0].GetBinContent(1)*isolatedSF\n",
    "    ## Calculate the number of events with nonPrompt photons, using the nonPromptSF\n",
    "    nonPromptRate = mc[1].GetBinContent(1)*nonPromptSF\n",
    "   \n",
    "    totalRate = (isolatedRate + nonPromptRate)\n",
    "\n",
    "    if not status==0:\n",
    "        print (f\"Error in fit while processing {syst} sample: exit status {status}\")\n",
    "    \n",
    "    ## Now that we know the number of events with isolated photons and the total number of events, we can calculate the photon Purity\n",
    "    phoPurity = isolatedRate/totalRate\n",
    "\n",
    "    ## Get the error on the fit parameter for isolated and nonprompt category\n",
    "    fitError_iso = fit.GetFitter().Result().ParError(0)\n",
    "    fitError_np = fit.GetFitter().Result().ParError(1)\n",
    "    \n",
    "    ## Calculate the error on isolatedRate and nonPromptRate\n",
    "    isoError = data.Integral()*fitError_iso*mc[0].GetBinContent(1)/mc[0].Integral()\n",
    "    npError = data.Integral()*fitError_np*mc[1].GetBinContent(1)/mc[1].Integral()\n",
    "\n",
    "    ## Now we can also calculate the error on photon Purity\n",
    "    phoPurityErr = ((isoError * (1 + phoPurity) / totalRate)**2 + (npError*phoPurity/totalRate)**2)**0.5\n",
    "\n",
    "    ## Fill the dictionary \"results\" with the photonPurity and error in photonPurity for each systematic\n",
    "    results[syst] = (phoPurity, phoPurityErr)    \n",
    "\n",
    "    del fit\n",
    "\n",
    "\n",
    "pp = pprint.PrettyPrinter(indent=4)\n",
    "pprint.pprint(results)\n",
    "\n",
    "with open('photonPurity.json', 'w') as outputFile:\n",
    "    json.dump(results, outputFile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "coffeaenv",
   "language": "python",
   "name": "coffeaenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
