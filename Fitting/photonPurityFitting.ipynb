{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'FSRDown': (0.8714804615904945, 0.03908638719491785),\n",
      " 'FSRUp': (0.8777324306737154, 0.03886042417850106),\n",
      " 'ISRDown': (0.8731087837461092, 0.03875249129033622),\n",
      " 'ISRUp': (0.8772279253848131, 0.0390248598857202),\n",
      " 'JERDown': (0.8774461928692859, 0.0390577052233943),\n",
      " 'JERUp': (0.8397910910505433, 0.034698196601816375),\n",
      " 'JESDown': (0.877824661392386, 0.03915716635637195),\n",
      " 'JESUp': (0.8699352131992069, 0.038503855296627594),\n",
      " 'PDFDown': (0.8756400421521499, 0.039150523312191744),\n",
      " 'PDFUp': (0.8757092336429694, 0.03877044136508483),\n",
      " 'Q2ScaleDown': (0.8770691984867508, 0.041128438185271544),\n",
      " 'Q2ScaleUp': (0.8722046236952317, 0.03678432286062166),\n",
      " 'btagWeight_heavyDown': (0.8755239905148744, 0.03905204854513101),\n",
      " 'btagWeight_heavyUp': (0.8757530076588049, 0.03883921067082902),\n",
      " 'btagWeight_lightDown': (0.8756210636244305, 0.038999787516500836),\n",
      " 'btagWeight_lightUp': (0.8756506251533842, 0.03888790869724424),\n",
      " 'eleEffWeightDown': (0.8756793291797107, 0.03900110460101198),\n",
      " 'eleEffWeightUp': (0.8755918927508829, 0.038886303528684725),\n",
      " 'muEffWeightDown': (0.8756373181498387, 0.038996508988085765),\n",
      " 'muEffWeightUp': (0.8756337226072407, 0.03889086640088348),\n",
      " 'nominal': (0.8756354787684235, 0.03894360556039796),\n",
      " 'puWeightDown': (0.878917948341039, 0.03900307021316691),\n",
      " 'puWeightUp': (0.8721073865598155, 0.038870908813886)}\n"
     ]
    }
   ],
   "source": [
    "#By Arun & Angel\n",
    "\n",
    "from ROOT import TFile, TFractionFitter, TObjArray\n",
    "import json\n",
    "import pprint\n",
    "\n",
    "## open root file, created from the SaveHistogramsToRoot step, containing charged hadron isolation distributions which have been grouped into isolated and nonprompt categories\n",
    "_file = TFile(\"../RootFiles/Isolation_Output.root\")\n",
    "\n",
    "## List of systematics\n",
    "systematics  = [\"nominal\",\n",
    "                \"FSRDown\",\n",
    "                \"FSRUp\",\n",
    "                \"ISRDown\",\n",
    "                \"ISRUp\",\n",
    "                \"JERDown\",\n",
    "                \"JERUp\",\n",
    "                \"JESDown\",\n",
    "                \"JESUp\",\n",
    "                \"PDFDown\",\n",
    "                \"PDFUp\",\n",
    "                \"Q2ScaleDown\",\n",
    "                \"Q2ScaleUp\",\n",
    "                \"btagWeight_heavyDown\",\n",
    "                \"btagWeight_heavyUp\",\n",
    "                \"btagWeight_lightDown\",\n",
    "                \"btagWeight_lightUp\",\n",
    "                \"eleEffWeightDown\",\n",
    "                \"eleEffWeightUp\",\n",
    "                \"muEffWeightDown\",\n",
    "                \"muEffWeightUp\",\n",
    "                \"puWeightDown\",\n",
    "                \"puWeightUp\",\n",
    "]\n",
    "\n",
    "results = {}\n",
    "\n",
    "## Get data from the input root file\n",
    "data = _file.Get(\"dataObs\")\n",
    "\n",
    "## Loop over the list of systematics\n",
    "for syst in systematics:\n",
    "    \n",
    "    ## Add histograms from Isolated and NonPrompt categories to the array 'mc'\n",
    "    mc = TObjArray(2)\n",
    "    \n",
    "    mc.Add(_file.Get(\"Isolated_\"+syst))\n",
    "    mc.Add(_file.Get(\"NonPrompt_\"+syst))\n",
    "   \n",
    "     ## Fit the MC histograms to data \n",
    "    fit = TFractionFitter(data,mc,\"q\")\n",
    "    \n",
    "    ## fit.Fit() actually performs the fit\n",
    "    ## check the fit status\n",
    "    status = int(fit.Fit())\n",
    "    \n",
    "    ## status==0 corresponds to fits that converged, and we can then obtain the fit result \n",
    "    fitResults = (fit.GetFitter().Result().Parameters()[0],fit.GetFitter().Result().Parameters()[1])\n",
    "    \n",
    "    ## Calculating the scale factor for isolated photons \n",
    "    isolatedSF  = data.Integral()*fitResults[0]/mc[0].Integral()\n",
    "    \n",
    "    ## Similarly, calculate the scale factor for the nonprompt photons\n",
    "    nonPromptSF = data.Integral()*fitResults[1]/mc[1].Integral()\n",
    "    \n",
    "    ## Calculate the number of events with isolated photons, using the isolatedSF\n",
    "    isolatedRate = mc[0].GetBinContent(1)*isolatedSF\n",
    "    ## Calculate the number of events with nonPrompt photons, using the nonPromptSF\n",
    "    nonPromptRate = mc[1].GetBinContent(1)*nonPromptSF\n",
    "   \n",
    "    totalRate = (isolatedRate + nonPromptRate)\n",
    "\n",
    "    if not status==0:\n",
    "        print (f\"Error in fit while processing {syst} sample: exit status {status}\")\n",
    "    \n",
    "    ## Now that we know the number of events with isolated photons and the total number of events, we can calculate the photon Purity\n",
    "    phoPurity = isolatedRate/totalRate\n",
    "\n",
    "    ## Get the error on the fit parameter for isolated and nonprompt category\n",
    "    fitError_iso = fit.GetFitter().Result().ParError(0)\n",
    "    fitError_np = fit.GetFitter().Result().ParError(1)\n",
    "    \n",
    "    ## Calculate the error on isolatedRate and nonPromptRate\n",
    "    isoError = data.Integral()*fitError_iso*mc[0].GetBinContent(1)/mc[0].Integral()\n",
    "    npError = data.Integral()*fitError_np*mc[1].GetBinContent(1)/mc[1].Integral()\n",
    "\n",
    "    ## Now we can also calculate the error on photon Purity\n",
    "    phoPurityErr = ((isoError * (1 + phoPurity) / totalRate)**2 + (npError*phoPurity/totalRate)**2)**0.5\n",
    "\n",
    "    ## Fill the dictionary \"results\" with the photonPurity and error in photonPurity for each systematic\n",
    "    results[syst] = (phoPurity, phoPurityErr)    \n",
    "\n",
    "    del fit\n",
    "\n",
    "\n",
    "pp = pprint.PrettyPrinter(indent=4)\n",
    "pprint.pprint(results)\n",
    "\n",
    "with open('photonPurity.json', 'w') as outputFile:\n",
    "    json.dump(results, outputFile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "coffeaenv",
   "language": "python",
   "name": "coffeaenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
